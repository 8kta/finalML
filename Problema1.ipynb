{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final\n",
    "## Analisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "from sklearn import datasets\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we read the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('problem1.csv',sep=',',header='infer') \n",
    "db = data_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_training</th>\n",
       "      <th>Y_training</th>\n",
       "      <th>X_test</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>22.067387</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.024049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.97</td>\n",
       "      <td>19.944915</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.885408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.94</td>\n",
       "      <td>18.062490</td>\n",
       "      <td>2.10</td>\n",
       "      <td>7.578968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.91</td>\n",
       "      <td>16.384313</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.439467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.88</td>\n",
       "      <td>14.567798</td>\n",
       "      <td>2.20</td>\n",
       "      <td>9.554611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_training  Y_training  X_test    Y_test\n",
       "0       -2.00   22.067387    2.00  6.024049\n",
       "1       -1.97   19.944915    2.05  6.885408\n",
       "2       -1.94   18.062490    2.10  7.578968\n",
       "3       -1.91   16.384313    2.15  8.439467\n",
       "4       -1.88   14.567798    2.20  9.554611"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = db.loc[:,'X_training']\n",
    "y_train = db.loc[:,'Y_training']\n",
    "x_test = db.loc[:,'X_test']\n",
    "y_test = db.loc[:,'Y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show dataframe statistics description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.transpose of        X_training  Y_training     X_test     Y_test\n",
       "count  134.000000  134.000000  21.000000  21.000000\n",
       "mean    -0.005000    4.467058   2.500000  24.051462\n",
       "std      1.164796    4.725730   0.310242  15.829402\n",
       "min     -2.000000   -3.215449   2.000000   6.024049\n",
       "25%     -1.002500    1.025247   2.250000  10.845279\n",
       "50%     -0.005000    4.939851   2.500000  19.726772\n",
       "75%      0.992500    7.447520   2.750000  34.523070\n",
       "max      1.990000   22.067387   3.000000  57.061905>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = db.describe()\n",
    "#data.pop('MPG')\n",
    "data = data.transpose\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pol_data_test\n",
    "pol_train = pd.DataFrame.from_dict(pol_data_train , orient='columns')\n",
    "pol_test = pd.DataFrame.from_dict(pol_data_test , orient='columns').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression(BaseEstimator):\n",
    "    def __init__(self, deg=None):\n",
    "        self.deg = deg\n",
    "    \n",
    "    def fit(self, X, y, deg=None):\n",
    "        self.model = LinearRegression(fit_intercept=False)\n",
    "        self.model.fit(np.vander(X, N=self.deg + 1), y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(np.vander(x, N=self.deg + 1))\n",
    "    \n",
    "    @property\n",
    "    def coef_(self):\n",
    "        return self.model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PolynomialRegression()\n",
    "degrees = np.arange(1, 25)\n",
    "cv_model = GridSearchCV(estimator,\n",
    "                        param_grid={'deg': degrees},\n",
    "                        scoring='neg_mean_squared_error')\n",
    "cv_model.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'deg': 4},\n",
       " array([ 1.99588109, -3.00869471, -5.99141415,  8.02956741,  6.0000592 ]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.best_params_, cv_model.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the mean values from X_training and Y_traing are far away;  -0.005000 and 4.467058. But the standard deviation show that the confidence interval of each is not disjoint of the other, so we can decide not to standarize the data.\n",
    "\n",
    "Then we prepare the data for the grade of polynomial we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What grade of polynomial do you want?\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "X_test_sin_na = pd.DataFrame(x_test).dropna()\n",
    "Y_test_sin_na = pd.DataFrame(y_test).dropna()\n",
    "\n",
    "#matriz para el polinomio\n",
    "pol_data_train = {}\n",
    "pol_data_test = {}\n",
    "alphabet_string = string.ascii_lowercase\n",
    "gr = input('What grade of polynomial do you want?\\n')\n",
    "\n",
    "gr = int(gr)\n",
    "for a in range(1,gr+1,1):\n",
    "    no = alphabet_string[a-1]\n",
    "    train = {no : x_train**a }\n",
    "    test = {no : x_test**a }\n",
    "    pol_data_train.update(train)\n",
    "    pol_data_test.update(test)\n",
    "    \n",
    " #pol_data_test\n",
    "pol_train = pd.DataFrame.from_dict(pol_data_train , orient='columns')\n",
    "pol_test = pd.DataFrame.from_dict(pol_data_test , orient='columns').dropna()   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresiones\n",
    "### Modelo Lasso\n",
    "We prepare lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalm = input('What alpha parameter do you want?\\n')\n",
    "while True:\n",
    "    try:\n",
    "        alph1 = float(alphalm)\n",
    "        print('The Lasso model with parameter',alph1,'is:')\n",
    "        break\n",
    "    except:\n",
    "        print('The alpha must be a number.')\n",
    "        alphalm = input('What alpha parameter do you want?\\n')\n",
    "        \n",
    "        \n",
    "lm = Lasso(alpha=float(alphalm), max_iter=1e6)\n",
    "lm.fit(pol_train, y_train)\n",
    "salida = pd.DataFrame(lm.predict(pol_test))\n",
    "salida.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Los coeficientes del polinomio son: \\n')\n",
    "for b in range(0,len(lm.coef_)):\n",
    "    print(lm.coef_[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pol_test.a, salida,'b', alpha=.6 , label='Prediction')\n",
    "plt.plot(pol_test.a, pd.DataFrame(y_test).dropna() ,'r--', label='Data')\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.xlabel(no)\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "We will explore different polynomials and check which provides the best fitting as well as the least AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to avoid division by zero while doing np.log10\n",
    "EPSILON = 1e-4\n",
    "\n",
    "# LassoLarsIC: least angle regression with BIC/AIC criterion\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "t1 = time.time()\n",
    "model_bic.fit(pol_train, y_train)\n",
    "t_bic = time.time() - t1\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(pol_train, y_train)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    criterion_ = model.criterion_\n",
    "    plt.semilogx(model.alphas_ + EPSILON, criterion_, '--', color=color,\n",
    "                 linewidth=3, label='%s criterion' % name)\n",
    "    plt.axvline(model.alpha_ + EPSILON, color=color, linewidth=3,\n",
    "                label='alpha: %s estimate' % name)\n",
    "    plt.xlabel(r'$\\alpha$')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection (training time %.3fs)'\n",
    "          % t_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV: coordinate descent\n",
    "\n",
    "# Compute paths\n",
    "print(\"Computing regularization path using the coordinate descent lasso...\")\n",
    "t1 = time.time()\n",
    "model = LassoCV(cv=20).fit(pol_train, y_train)\n",
    "t_lasso_cv = time.time() - t1\n",
    "\n",
    "# Display results\n",
    "plt.figure()\n",
    "ymin, ymax = 0, 40\n",
    "plt.semilogx(model.alphas_ + EPSILON, model.mse_path_, ':')\n",
    "plt.plot(model.alphas_ + EPSILON, model.mse_path_.mean(axis=-1), 'k',\n",
    "         label='Average across the folds', linewidth=2)\n",
    "plt.axvline(model.alpha_ + EPSILON, linestyle='--', color='k',\n",
    "            label='alpha: CV estimate')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('Mean square error')\n",
    "plt.title('Mean square error on each fold: coordinate descent '\n",
    "          '(train time: %.2fs)' % t_lasso_cv)\n",
    "plt.axis('tight')\n",
    "plt.ylim(ymin, ymax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoLarsCV: least angle regression\n",
    "\n",
    "# Compute paths\n",
    "print(\"Computing regularization path using the Lars lasso...\")\n",
    "t1 = time.time()\n",
    "model = LassoLarsCV(cv=20).fit(pol_train, y_train)\n",
    "t_lasso_lars_cv = time.time() - t1\n",
    "\n",
    "# Display results\n",
    "plt.figure()\n",
    "plt.semilogx(model.cv_alphas_ + EPSILON, model.mse_path_, ':')\n",
    "plt.semilogx(model.cv_alphas_ + EPSILON, model.mse_path_.mean(axis=-1), 'k',\n",
    "             label='Average across the folds', linewidth=2)\n",
    "plt.axvline(model.alpha_, linestyle='--', color='k',\n",
    "            label='alpha CV')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('Mean square error')\n",
    "plt.title('Mean square error on each fold: Lars (train time: %.2fs)'\n",
    "          % t_lasso_lars_cv)\n",
    "plt.axis('tight')\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(EPSILON, 1,.001)\n",
    "cv_model = GridSearchCV(lm,\n",
    "                        param_grid={'alpha': degrees},\n",
    "                        scoring='neg_mean_squared_error')\n",
    "cv_model.fit(pol_test, Y_test_sin_na);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in lm.get_params().keys():\n",
    "#    print(param)\n",
    "cv_model.best_params_, cv_model.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
